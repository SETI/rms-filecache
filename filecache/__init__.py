##########################################################################################
# filecache/__init__.py
##########################################################################################

"""The purpose of the `filecache` module is to abstract away the location where files
used or generated by a program are stored. Files can be on the local file system, in
Google Cloud Storage, on Amazon Web Services S3, or on a webserver. When files to be read
are on the local file system, they are simply accessed in-place. Otherwise, they are
downloaded from the remote source to a local temporary directory. When files to be written
are on the local file system, they are simply written in-place. Otherwise, they are
written to a local temporary directory and then uploaded to the remote location (it is not
possible to upload to a webserver). When a cache is no longer needed, it is deleted from
the local disk.

The top-level file organization is provided by the :class:`FileCache` class. A
:class:`FileCache` instance is used to specify a particular **sharing policy** and
**lifetime**. For example, a cache could be private to the current process and group a set
of files that all have the same basic purpose. Once these files have been (downloaded and)
read, they are deleted as a group. Another cache could be shared among all processes on
the current machine and group a set of files that are needed by multiple processes, thus
allowing them to be downloaded from a remote source only one time, saving time and
bandwidth.

A :class:`FileCache` can be instantiated either directly or as a context manager. When
instantiated directly, the programmer is responsible for calling
:meth:`FileCache.clean_up` directly to delete the cache when finished. In addition, a
non-shared cache will be deleted on program exit. When instantiated as a context manager,
a non-shared cache is deleted on exit from the context. See the class documentation for
full details.

Usage examples::

    from filecache import FileCache
    with FileCache() as fc:  # Use as context manager
        # Also use open() as a context manager
        with fc.open('gs://rms-filecache-tests/subdir1/subdir2a/binary1.bin', 'rb',
                     anonymous=True) as fp:
            bin1 = fp.read()
        with fc.open('s3://rms-filecache-tests/subdir1/subdir2a/binary1.bin', 'rb',
                     anonymous=True) as fp:
            bin2 = fp.read()
        assert bin1 == bin2
    # Cache automatically deleted here

    fc = FileCache()  # Use without context manager
    # Also retrieve file without using open context manager
    path1 = fc.retrieve('gs://rms-filecache-tests/subdir1/subdir2a/binary1.bin',
                        anonymous=True)
    with open(path1, 'rb') as fp:
        bin1 = fp.read()
    path2 = fc.retrieve('s3://rms-filecache-tests/subdir1/subdir2a/binary1.bin',
                        anonymous=True)
    with open(path2, 'rb') as fp:
        bin2 = fp.read()
    fc.clean_up()  # Cache manually deleted here
    assert bin1 == bin2

    # Write a file to a bucket and read it back
    with FileCache() as fc:
        with fc.open('gs://my-writable-bucket/output.txt', 'w') as fp:
            fp.write('A')
    # The cache will be deleted here so the file will have to be downloaded
    with FileCache() as fc:
        with fc.open('gs://my-writable-bucket/output.txt', 'r') as fp:
            print(fp.read())

A :class:`FileCachePrefix` instance can be used to encapsulate the storage prefix string,
as well as any subdirectories, plus various arguments such as `anonymous` and `time_out`
that can be specified to each `exists`, `retrieve`, or `upload` method. Thus using one
of these instances can simplify the use of a :class:`FileCache` by allowing the user to
only specify the relative part of the path to be operated on, and to not specify various
other parameters at each method call site.

Compare this example to the one above::

    from filecache import FileCache
    with FileCache() as fc:  # Use as context manager
        # Use GS by specifying the bucket name and one directory level
        pfx1 = fc.new_prefix('gs://rms-filecache-tests/subdir1', anonymous=True)
        # Use S3 by specifying the bucket name and two directory levels
        pfx2 = fc.new_prefix('s3://rms-filecache-tests/subdir1/subdir2a', anonymous=True)
        # Access GS using a directory + filename (since only one directory level
        # was specified by the prefix)
        # Also use open() as a context manager
        with pfx1.open('subdir2a/binary1.bin', 'rb') as fp:
            bin1 = fp.read()
        # Access S3 using a filename only (since two directory levels were already
        # specified by the prefix))
        with pfx2.open('binary1.bin', 'rb') as fp:
            bin2 = fp.read()
        assert bin1 == bin2
    # Cache automatically deleted here

A benefit of the abstraction is that different environments can access the same files in
different ways without needing to change the program code. For example, consider a program
that needs to access the file ``COISS_2xxx/COISS_2001/voldesc.cat`` from the NASA PDS
archives. This file might be stored on the local disk in the user's home directory in a
subdirectory called ``pds3-holdings``. Or if the user does not have a local copy, it is
accessible from a webserver at
``https://pds-rings.seti.org/holdings/volumes/COISS_2xxx/COISS_2001/voldesc.cat``.
Finally, it could be accessible from Google Cloud Storage from the ``rms-node-holdings``
bucket at
``gs://rms-node-holdings/pds3-holdings/volumes/COISS_2xxx/COISS_2001/voldesc.cat``. Before
running the program, an environment variable could be set to one of these values::

    $ export PDS3_HOLDINGS_SRC="~/pds3-holdings"
    $ export PDS3_HOLDINGS_SRC="https://pds-rings.seti.org/holdings"
    $ export PDS3_HOLDINGS_SRC="gs://rms-node-holdings/pds3-holdings"

Then the program could be written as::

    from filecache import FileCache
    import os
    with FileCache() as fc:
        pfx = fc.new_prefix(os.getenv('PDS3_HOLDINGS_SRC'))
        with pfx.open('volumes/COISS_2xxx/COISS_2001/voldesc.cat', 'r') as fp:
            contents = fp.read()
    # Cache automatically deleted here

If the program was going to be run multiple times in a row, or multiple copies were going
to be run simultaneously, marking the cache as shared would allow all of the processes to
share the same copy, thus requiring only a single download no matter how many times the
program was run::

    from filecache import FileCache
    import os
    with FileCache(shared=True) as fc:
        pfx = fc.new_prefix(os.getenv('PDS3_HOLDINGS_DIR'))
        with pfx.open('volumes/COISS_2xxx/COISS_2001/voldesc.cat', 'r') as fp:
            contents = fp.read()
    # Cache not deleted here; must be deleted manually using fc.clean_up(final=True)
    # If not deleted manually, the shared cache will persist until the temporary
    # directory is purged by the operating system (which may be never)

Finally, there are four classes that allow direct access to the four possible storage
locations without invoking any caching behavior: :class:`FileCacheSourceFile`,
:class:`FileCacheSourceHTTP`, :class:`FileCacheSourceGS`, and :class:`FileSourceCacheS3`::

    from filecache import FileCacheSourceGS
    src = FileCacheSourceGS('gs://rms-filecache-tests', anonymous=True)
    src.retrieve('subdir1/subdir2a/binary1.bin', 'local_file.bin')
"""

import typing

if not typing.TYPE_CHECKING:
    try:
        from ._version import __version__
    except ImportError:  # pragma: no cover - only present when building a package
        __version__ = 'Version unspecified'

from .file_cache import (get_global_logger,    # noqa: ignore E401
                         register_filecachesource,
                         set_easy_logger,
                         set_global_logger,
                         FileCache)
from .file_cache_prefix import FileCachePrefix  # noqa: ignore E401
from .file_cache_source import (FileCacheSource,  # noqa: ignore E401
                                FileCacheSourceFile,
                                FileCacheSourceHTTP,
                                FileCacheSourceGS,
                                FileCacheSourceS3)

__all__ = ['get_global_logger',
           'register_filecachesource',
           'set_easy_logger',
           'set_global_logger',
           'FileCache',
           'FileCachePrefix',
           'FileCacheSource',
           'FileCacheSourceFile',
           'FileCacheSourceHTTP',
           'FileCacheSourceGS']
